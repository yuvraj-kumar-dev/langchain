{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c209423",
   "metadata": {},
   "source": [
    "# Langchain Tutorial : Creating a Simple Q&A Chatbot (PART - I)\n",
    "\n",
    "## In this tutorial, you will get to know how can someone create a simple Q&A Chatbot using OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dc3497",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "The first step to begin is to first create a Virtual Environment, you can see below how can you create one in your windows:-\n",
    "\n",
    "Open the terminal of your project folder and then:-\n",
    "\n",
    "1) pip install virtualenv (intall virtualenv)\n",
    "2) Set-ExecutionPolicy RemoteSigned -Scope CurrentUser  (Change the policies)\n",
    "3) python -m venv env (create a virtual environment folder named \"env\")\n",
    "\n",
    "> To activate your virtual environment : `.\\env\\Scripts\\activate`\n",
    "\n",
    "By following the above easy steps you can easily create virtual environment for your project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2eb388",
   "metadata": {},
   "source": [
    "### Folder Structure\n",
    "\n",
    "> 1) app.py (main app we will run)\n",
    "> 2) env/ (virtual environment)\n",
    "> 3) .env (file to store all the environment variables)\n",
    "> 4) requirements.txt (file to store all the required libraries used in this project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d45ee",
   "metadata": {},
   "source": [
    "### Setting up requirements.txt and .env\n",
    "\n",
    "1) Now, we have to install required libraries for our project. For this you can insall all the required libraries one by one using pip and then generate `requirements.txt` file using `pip freeze > requirements.txt` OR you can simply add the below libraries in `requirements.txt` and then run `pip install -r requirements.txt`\n",
    "\n",
    "> 1) langchain_openai\n",
    "> 2) langchain_core\n",
    "> 3) python-dotenv\n",
    "> 4) streamlit\n",
    "> 5) langchain_community\n",
    "> 6) langserve\n",
    "\n",
    "2) After setting up the requirements.txt file and installing all the required libraries for our project, our next step is to get all the required environment variables for our project.\n",
    "\n",
    "> `LANGCHAIN_API_KEY = \"your api key\"`\n",
    "> `OPENAI_API_KEY = \"your api key\"`\n",
    "> `LANCHAIN_PROJECT = \"your project name\"`\n",
    "\n",
    "Put all these environment variable inside your .env file and paste your own API_KEY in the required spaces.\n",
    "\n",
    "To get LANGCHAIN_API_KEY first go to langchain's official website and sign up there and after signing up you will get redirected to a dashboard `Now you will get why langchain is so cool, here you will see that langchain provides you a whole ecosystem whrere you can easily track and monitor your project` This ecosystem is provided by the langsmith `LangSmith helps you to trace and evaluate your language model applications and intelligent agents to help you move from prototype to production`\n",
    "\n",
    "> Now go to `settings` in your dashboard and easily create a new api key and copy your api key and put it in the required field.\n",
    "\n",
    "> Now create a project there and name your project and then use the same name in the .env file for the LANGCHAI_PROJECT variable\n",
    "\n",
    "> Now go to openAI and get your API Key\n",
    "\n",
    "after setting all these things now we are ready to move to the next step where we will learn to code the Q&A chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf8246d",
   "metadata": {},
   "source": [
    "### app.py\n",
    "\n",
    "``` python\n",
    " from langchain_openai import ChatOpenAI #To interact with the OpenAI LLMs\n",
    " from langchain_core.prompts import ChatPromptTemplate #For custom prompts\n",
    " from langchain_core.output_parsers import StrOutputParser #To control how the output would be displayed\n",
    "\n",
    " import streamlit as st\n",
    " import os\n",
    " from dotenv import load_dotenv\n",
    "\n",
    " load_dotenv()\n",
    "\n",
    " #Now after importing all the required functions and libraries we will now call the environment variables\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#LangSmith Tracking\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACKING_V2\"] = \"true\"\n",
    "\n",
    "#Chatbot\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Provide response to user\"), #system prompt, change acc to your requirements\n",
    "\n",
    "        (\"user\", \"Question:{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "#streamlit UI\n",
    "\n",
    "st.title(\"Q&A CHATBOT USING OPENAI\")\n",
    "input_text = st.text_input(\"Ask something from the chatbot\")\n",
    "\n",
    "#openai LLM call\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\") #call the model acc to your requirements\n",
    "output = StrOutputParser() #RETURN OUTPUT AS A STRING\n",
    "\n",
    "#chain\n",
    "\n",
    "chain = prompt|llm|output\n",
    "\n",
    "if input_text:\n",
    "    st.write(chain.invoke({'question': input_text}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0808700a",
   "metadata": {},
   "source": [
    "### Running the chatbot\n",
    "\n",
    "`streamlit run app.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dbb4ec",
   "metadata": {},
   "source": [
    "### Thankyou\n",
    "\n",
    "So Now you can enter some questions and check the response by the llm but you can also check and monitor your chatbot with the help of `langsmith` go to the langchain dashboard and under your projects go to your project and here you can get all the information of your chatbot like the cost of the responses, what were the questions asked from the chatbot, how the chatbot responded which is very helpful for us. We can also customize this also which we will learn in the next chapters.\n",
    "\n",
    "> NOTE: In this Q&A bot we used paid LLM but we can also use open-source free LLMs for responses which we will learn in the next part of this chapter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
