{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11706180",
   "metadata": {},
   "source": [
    "# WELCOME BACK : Q&A Chatbot using OLLAMA OPEN-SOURCE LLMs (PART - II)\n",
    "\n",
    "In this tutorial we will learn how we can easily use ollama open source llms locally in our systems and use these to create a basic **Q&A** chatbot application\n",
    "\n",
    "> The folder structure will be same as of PART - I but in `.env` file, we will not require openAI API KEY this time as we will be using OLLAMA LLMs\n",
    "\n",
    "For making Q&A Chatbot using OLLAMA, we have to include some minor changes in our `app.py` rest everything will be same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b7a1c5",
   "metadata": {},
   "source": [
    "## app.py\n",
    "\n",
    "```python\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate #For custom prompts\n",
    "from langchain_core.output_parsers import StrOutputParser #To control how the output would be displayed\n",
    "from langchain_community.llms import ollama #for interacting with ollama llms\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "#Langsmith Tracking\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACKING_V2\"] = \"true\"\n",
    "\n",
    "#Chatbot\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "[\n",
    "    (\"system\", \"You are a helpful assistant. Provide response to user\"), #system prompt, change acc to your requirements\n",
    "\n",
    "    (\"user\", \"Question:{question}\")\n",
    "]\n",
    ")\n",
    "\n",
    "#streamlit UI\n",
    "\n",
    "st.title(\"Q&A CHATBOT USING OLLAMA\")\n",
    "input_text = st.text_input(\"Ask something from the chatbot\")\n",
    "\n",
    "#openai LLM call\n",
    "\n",
    "llm = ollama(model=\"USE ANY OLLAMA MODEL YOU HAVE INSTALLED IN YOUR SYSTEM\") #call the model acc to your requirements\n",
    "output = StrOutputParser() #RETURN OUTPUT AS A STRING\n",
    "\n",
    "#chain\n",
    "\n",
    "chain = prompt|llm|output\n",
    "\n",
    "if input_text:\n",
    "    st.write(chain.invoke({'question': input_text}))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
